## 텐서의 속성(Attribute)
텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.

```
tensor = torch.rand(3,4)

tensor.shape  #3,4
tensor.dtype  #torch.float32
tensor.device  #cpu
```

## 텐서 연산(Operation)

### 장치 변경
 연산들은 (일반적으로 CPU보다 빠른) GPU에서 실행할 수 있습니다.

◻ Colab을 사용한다면, Edit > Notebook Settings 에서 GPU를 할당할 수 있습니다.

기본적으로 텐서는 CPU에 생성됩니다. `.to`메소드를 사용하면 (GPU의 가용성(availability)을 확인한 뒤) GPU로 텐서를 명시적으로 이동할 수 있습니다. 

```
# GPU가 존재하면 텐서를 이동합니다
if torch.cuda.is_available():
    tensor = tensor.to("cuda")
```
### 텐서 합치기
`torch.cat` : numpy 의 concatenate() 와 Pandas 의 concat() 함수와 유사.


```
a = [1,2,3,4]
b = [5,6,7,8]

>>>np.concatenate([
    np.array(a),
    np.array(b)], axis = 0)
[[1 2 3 4]
 [5 6 7 8]]

>>>pd.concat([ 
    pd.DataFrame(a), 
    pd.DataFrame(b)], axis=0))
   0  1  2  3
0  1  2  3  4
0  5  6  7  8

>>>torch.cat([ 
    torch.tensor(a), 
    torch.tensor(b) ], dim=0))
tensor([[1, 2, 3, 4],
        [5, 6, 7, 8]])

```
#### dim 인자는 두 텐서를 어느방향으로 병합할지 결정한다. 
> dim = 0

feature들의 갯수를 유지한 채로 Row 개수가 증가한다.
즉, Tensor의 Batch Size가 증가한다.

3차원의 Tensor라면 첫번째 차원 즉 채널의 수가 늘어난다.
> dim = 1

두번째 차원의 방향으로 Tensor들이 추가된다. 2차원의 Tensor라면 Column 즉, Feature의 개수가 증가하게 된다.
`[1,2,3,4]+[5,6,7,8] => [1,2,3,4,5,6,7,8]`

3차원의 Tensor라면 각 채널의 Row의 개수가 증가한다.

> dim = -1

가장 마지막 차원이 증가하는 방향으로 Tensor들이 병합한다.
즉, 2차원의 tensor라면 dim = 1과 dim = 2는 동일한 결과를 얻게 된다.

3차원의 텐서라면 Column의 개수가 증가한다.

---
`torch.stack` : 주어진 텐서들을 새로운 차원으로 합친다. <br> 2차원 텐서 두개를 3차원 텐서로 합치는 방법
```
>>> x = torch.randn(2, 3)
>>> x
tensor([[ 0.3367,  0.1288,  0.2345],
        [ 0.2303, -1.1229, -0.1863]])
>>> x = torch.stack((x, x)) 
>>> x
tensor([[[ 0.3367,  0.1288,  0.2345],
         [ 0.2303, -1.1229, -0.1863]],

        [[ 0.3367,  0.1288,  0.2345],
         [ 0.2303, -1.1229, -0.1863]]])
```
## 산술연산

### 행렬 곱 연산
조건: 행렬 내적 조건 만족
```
#셋 다 같은 의미
ans = t1 @ t2
ans = t1.matmul(t2)
torch.matmul(t1,t2,out=ans)
```

## 요소별 곱 연산
조건: 두 텐서의 shape 동일
```
# 셋 다 같은 의미
ans = t1 * t2
ans = t1.mul(t2)
torch.mul(t1,t2,out=ans)
```
